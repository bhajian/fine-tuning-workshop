{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nemotron Phishing Detection Workshop\n",
    "\n",
    "This notebook walks through the full fine-tuning workflow on the Enron dataset:\n",
    "1. Download the dataset\n",
    "2. Convert to JSONL\n",
    "3. Fine-tune Nemotron with LoRA\n",
    "4. Evaluate the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f33ff6",
   "metadata": {},
   "source": [
    "## Environment setup (run in terminal)\n",
    "Create a virtual environment and install dependencies from the shell.\n",
    "\n",
    "```bash\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "python -m pip install --upgrade pip\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68e190a",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "If you're running in a fresh environment, install the workshop requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e705b7",
   "metadata": {},
   "source": [
    "## Configure Kaggle API\n",
    "Export your Kaggle credentials before downloading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea81ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = 'YYYYYYYYYY'\n",
    "os.environ['KAGGLE_KEY'] = 'XXXXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading wcukierski/enron-email-dataset to ../data/raw...\n",
      "Dataset URL: https://www.kaggle.com/datasets/wcukierski/enron-email-dataset\n",
      "Download completed, but maildir was not found. Check the output directory.\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/download_dataset.py --output_dir ../data/raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to JSONL\n",
    "This uses a simple keyword heuristic to label phishing vs benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d065cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing emails: 517401it [05:59, 1440.15it/s]\n",
      "Wrote JSONL files to ../data/processed\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/prepare_jsonl.py --input_csv ../data/raw/emails.csv --output_dir ../data/processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e597600",
   "metadata": {},
   "source": [
    "## Inspect dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed04f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 50000,\n",
       " 'train': 40000,\n",
       " 'val': 5000,\n",
       " 'test': 5000,\n",
       " 'phishing': 6567,\n",
       " 'benign': 43433}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "stats = json.loads(Path('../data/processed/stats.json').read_text())\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0fdcd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 5000,\n",
       " 'train': 4000,\n",
       " 'val': 500,\n",
       " 'test': 500,\n",
       " 'phishing': 649,\n",
       " 'benign': 4351}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trim dataset to 10% to target ~1 hour training on L4\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "src_dir = Path('../data/processed')\n",
    "dst_dir = Path('../data/processed_small')\n",
    "dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "seed = 42\n",
    "fraction = 0.1\n",
    "\n",
    "def sample_jsonl(src, dst, fraction, seed):\n",
    "    lines = Path(src).read_text().splitlines()\n",
    "    rng = random.Random(seed)\n",
    "    k = max(1, int(len(lines) * fraction))\n",
    "    sample = rng.sample(lines, k)\n",
    "    Path(dst).write_text('\\n'.join(sample) + '\\n')\n",
    "    return k\n",
    "\n",
    "counts = {}\n",
    "counts['train'] = sample_jsonl(src_dir / 'train.jsonl', dst_dir / 'train.jsonl', fraction, seed)\n",
    "counts['val'] = sample_jsonl(src_dir / 'val.jsonl', dst_dir / 'val.jsonl', fraction, seed)\n",
    "counts['test'] = sample_jsonl(src_dir / 'test.jsonl', dst_dir / 'test.jsonl', fraction, seed)\n",
    "\n",
    "def count_labels(path):\n",
    "    stats = {'phishing': 0, 'benign': 0, 'total': 0}\n",
    "    for line in Path(path).read_text().splitlines():\n",
    "        if not line:\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        label = obj.get('label', '')\n",
    "        if label in stats:\n",
    "            stats[label] += 1\n",
    "        stats['total'] += 1\n",
    "    return stats\n",
    "\n",
    "train_stats = count_labels(dst_dir / 'train.jsonl')\n",
    "val_stats = count_labels(dst_dir / 'val.jsonl')\n",
    "test_stats = count_labels(dst_dir / 'test.jsonl')\n",
    "small_stats = {\n",
    "    'total': train_stats['total'] + val_stats['total'] + test_stats['total'],\n",
    "    'train': train_stats['total'],\n",
    "    'val': val_stats['total'],\n",
    "    'test': test_stats['total'],\n",
    "    'phishing': train_stats['phishing'] + val_stats['phishing'] + test_stats['phishing'],\n",
    "    'benign': train_stats['benign'] + val_stats['benign'] + test_stats['benign'],\n",
    "}\n",
    "(dst_dir / 'stats.json').write_text(json.dumps(small_stats, indent=2))\n",
    "small_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c962eb",
   "metadata": {},
   "source": [
    "## Evaluate the base model (run in terminal)\n",
    "Serve the base model first, then score the test set and save results to disk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8863e4f7",
   "metadata": {},
   "source": [
    "Terminal A (serve):\n",
    "```bash\n",
    "python scripts/serve.py --model_name nvidia/Nemotron-Mini-4B-Instruct --port 8000\n",
    "```\n",
    "\n",
    "Terminal B (evaluate):\n",
    "```bash\n",
    "python scripts/test_model.py --endpoint http://127.0.0.1:8000/predict \\\n",
    "  --test_file data/processed_small/test.jsonl \\\n",
    "  --max_samples 5000 \\\n",
    "  --output_file outputs/eval_base.json\n",
    "```\n",
    "\n",
    "Stop the server with Ctrl+C when done.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e72cc3c",
   "metadata": {},
   "source": [
    "## Fine-tune the model (run in terminal)\n",
    "Training can take hours, so run it from a shell instead of the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6065361",
   "metadata": {},
   "source": [
    "```bash\n",
    "python scripts/train.py --data_dir data/processed_small --output_dir outputs \\\n",
    "  --model_name nvidia/Nemotron-Mini-4B-Instruct --num_train_epochs 1 --max_seq_length 512\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ab8ffe",
   "metadata": {},
   "source": [
    "## Evaluate the fine-tuned model (run in terminal)\n",
    "Serve the adapter, then score the same test set and save results to disk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4630b828",
   "metadata": {},
   "source": [
    "Terminal A (serve):\n",
    "```bash\n",
    "python scripts/serve.py --model_name nvidia/Nemotron-Mini-4B-Instruct \\\n",
    "  --adapter_dir outputs/adapter --port 8000\n",
    "```\n",
    "\n",
    "Terminal B (evaluate):\n",
    "```bash\n",
    "python scripts/test_model.py --endpoint http://127.0.0.1:8000/predict \\\n",
    "  --test_file data/processed_small/test.jsonl \\\n",
    "  --max_samples 5000 \\\n",
    "  --output_file outputs/eval_tuned.json\n",
    "```\n",
    "\n",
    "Stop the server with Ctrl+C when done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa31152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "base = json.loads(Path(\"../outputs/eval_base.json\").read_text())\n",
    "tuned = json.loads(Path(\"../outputs/eval_tuned.json\").read_text())\n",
    "\n",
    "def fmt(result):\n",
    "    return f\"{result[\"accuracy\"]:.2%} ({result[\"correct\"]}/{result[\"total\"]})\"\n",
    "\n",
    "print(\"Base accuracy:\", fmt(base))\n",
    "print(\"Tuned accuracy:\", fmt(tuned))\n",
    "print(\"Absolute gain:\", f\"{(tuned[\"accuracy\"] - base[\"accuracy\"]) * 100:.2f} pp\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
